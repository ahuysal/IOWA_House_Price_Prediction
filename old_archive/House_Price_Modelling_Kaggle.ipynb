{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pprint\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.options.display.max_columns = 300\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV, BayesianRidge\n",
    "import xgboost as xgb\n",
    "import re\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model. MLR, Ridge, Lasso, ElasticNet, RandomForest, XGBoost\n",
    "model_list = ['MLR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (1460, 81)\n",
      "Test data shape: (1459, 80)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train data shape:\", train.shape)\n",
    "print(\"Test data shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "train = train[train['GrLivArea']<4000]\n",
    "\n",
    "# Estimate price per SF of Living Area. Remove the high and low end outliers \n",
    "# (This did not give better results but still can be used to provide a story for outlier detection and removal part)\n",
    "#myarr = (train['SalePrice'] / train['GrLivArea']).sort_values(ascending=False)\n",
    "#drop_index_high = myarr[myarr>250].index\n",
    "#drop_index_low = myarr[myarr<40].index\n",
    "#train.drop(drop_index_low, inplace=True)\n",
    "#train.drop(drop_index_high, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform target\n",
    "train['SalePrice'] = np.log(train['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilmiuysal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([train, test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Drop columns\n",
    "# Bsmt\n",
    "BsmtSumSF = df_concat[['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF']].sum(axis=1)\n",
    "print((df_concat['TotalBsmtSF'] == BsmtSumSF).all())\n",
    "df_concat.drop(['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF'], axis=1, inplace=True)\n",
    "\n",
    "house_sqft = df_concat[['1stFlrSF','2ndFlrSF','LowQualFinSF']].sum(axis=1)\n",
    "print((house_sqft == df_concat['GrLivArea']).all())\n",
    "df_concat.drop(['1stFlrSF','2ndFlrSF','LowQualFinSF'], axis=1, inplace=True)\n",
    "\n",
    "df_concat['TotalPorchSF'] = df_concat[['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','WoodDeckSF']].sum(axis=1)\n",
    "df_concat.drop(['OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch','WoodDeckSF'], axis=1, inplace=True)\n",
    "\n",
    "# MiscVal holds no value. Drop!\n",
    "df_concat.drop(['MiscVal'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some numerical variables are not continuous. They must be regarded as categorical variables:\n",
    "\n",
    "- MSSubClass\n",
    "- OverallQual\n",
    "- OverallCond\n",
    "- BsmtFullBath\t\n",
    "- BsmtHalfBath\t\n",
    "- FullBath\n",
    "- HalfBath\n",
    "- BedroomAbvGr\n",
    "- KitchenAbvGr\n",
    "- TotRmsAbvGrd\n",
    "- Fireplaces\n",
    "- GarageCars\n",
    "- YrSold\n",
    "\n",
    "Let's add them to the **categorical_features** dataframe, remove from the **numerical_features** dataframe and see the distributions of classes for each variable.\n",
    "\n",
    "Below columns need special attention. I will first bin them and then add to the categorical variables.\n",
    "- MoSold\n",
    "- YearBuilt\n",
    "- YearRemodAdd\n",
    "- GarageYrBlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In test dataset GarageYrBlt has a column with value of 2207. Update it to 2010 which is the max after 2207.\n",
    "df_concat.loc[df_concat['GarageYrBlt'] == 2207,'GarageYrBlt'] = 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Houses without a garage have NAs. Fill them with year 0. Then, bin.\n",
    "df_concat['GarageYrBlt'].fillna(0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GarageCars, BsmtFullBath, BsmtHalfBath column has very few nulls. Impute them with median before casting to category.\n",
    "med_GarageCars = df_concat['GarageCars'].median()\n",
    "df_concat['GarageCars'].fillna(med_GarageCars, inplace = True)\n",
    "\n",
    "med_BsmtFullBath = df_concat['BsmtFullBath'].median()\n",
    "df_concat['BsmtFullBath'].fillna(med_BsmtFullBath, inplace = True)\n",
    "\n",
    "med_BsmtHalfBath = df_concat['BsmtHalfBath'].median()\n",
    "df_concat['BsmtHalfBath'].fillna(med_BsmtHalfBath, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NA randomly using non-NA values of that column\n",
    "def fill_with_random(df2, column):\n",
    "    df = df2.copy()\n",
    "    df[column] = df[column].apply(lambda x: np.random.choice(df[column].dropna().values) if np.isnan(x) else x)\n",
    "    return df\n",
    "\n",
    "#med_GarageArea = df_concat['GarageArea'].median()\n",
    "#med_TotalBsmtSF = df_concat['TotalBsmtSF'].median()\n",
    "#med_MasVnrArea = df_concat['MasVnrArea'].median()\n",
    "#med_LotFrontage = df_concat['LotFrontage'].median()\n",
    "#df_concat['GarageArea'].fillna(med_GarageArea, inplace = True)\n",
    "#df_concat['TotalBsmtSF'].fillna(med_TotalBsmtSF, inplace = True)\n",
    "#df_concat['MasVnrArea'].fillna(med_MasVnrArea, inplace = True)\n",
    "#df_concat['LotFrontage'].fillna(med_LotFrontage, inplace = True)\n",
    "\n",
    "df_concat = fill_with_random(df_concat, 'GarageArea')\n",
    "df_concat = fill_with_random(df_concat, 'TotalBsmtSF')\n",
    "df_concat = fill_with_random(df_concat, 'MasVnrArea')\n",
    "df_concat = fill_with_random(df_concat, 'LotFrontage')\n",
    "\n",
    "# Extra null columns in the df_concat dataset. Impute with the most common class.\n",
    "df_concat['KitchenQual'].fillna(df_concat['KitchenQual'].value_counts().index[0], inplace = True)\n",
    "df_concat['Utilities'].fillna(df_concat['Utilities'].value_counts().index[0], inplace = True)\n",
    "df_concat['Functional'].fillna(df_concat['Functional'].value_counts().index[0], inplace = True)\n",
    "df_concat['SaleType'].fillna(df_concat['SaleType'].value_counts().index[0], inplace = True)\n",
    "df_concat['Exterior1st'].fillna(df_concat['Exterior1st'].value_counts().index[0], inplace = True)\n",
    "df_concat['Exterior2nd'].fillna(df_concat['Exterior2nd'].value_counts().index[0], inplace = True)\n",
    "df_concat['MSZoning'].fillna(df_concat['MSZoning'].value_counts().index[0], inplace = True)\n",
    "df_concat['Electrical'].fillna(df_concat['Electrical'].value_counts().index[0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead of binning, normalize\n",
    "# Note: Normalization did not help. Use them as they are.\n",
    "#df_concat['MasVnrArea'] = (df_concat['MasVnrArea'] - np.mean(df_concat['MasVnrArea'])) / np.std(df_concat['MasVnrArea'])\n",
    "#df_concat['TotalPorchSF'] = (df_concat['TotalPorchSF'] - np.mean(df_concat['TotalPorchSF'])) / np.std(df_concat['TotalPorchSF'])\n",
    "#df_concat['GarageArea'] = (df_concat['GarageArea'] - np.mean(df_concat['GarageArea'])) / np.std(df_concat['GarageArea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n",
    "# Set YearRemodAdd = 0 if YearRemodAdd == YearBuilt\n",
    "df_concat.loc[df_concat['YearRemodAdd'] == df_concat['YearBuilt'], 'YearRemodAdd'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.catplot(x='YearRemodAdd', y='SalePrice', data=df_concat, kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning\n",
    "df_concat['MoSold'] = pd.cut(df_concat['MoSold'], [1,4,8,12], include_lowest=True)\n",
    "df_concat['YearBuilt'] = pd.cut(df_concat['YearBuilt'], [1872,1950,1980,2000,2010], include_lowest=True)\n",
    "df_concat['YearRemodAdd'] = pd.cut(df_concat['YearRemodAdd'], [0,1,1980,2000,2010], include_lowest=True)\n",
    "#df_concat['YearRemodAdd'] = pd.cut(df_concat['YearRemodAdd'], [1950,1980,2000,2010], include_lowest=True)\n",
    "df_concat['GarageYrBlt'] = pd.cut(df_concat['GarageYrBlt'], [0,1894,1950,1980,2000,2010], include_lowest=True)\n",
    "#df_concat['MasVnrArea'] = pd.cut(df_concat['MasVnrArea'], [0,100,300,1600], include_lowest=True)\n",
    "#df_concat['TotalPorchSF'] = pd.cut(df_concat['TotalPorchSF'], [0,100,300,1424], include_lowest=True)\n",
    "#df_concat['GarageArea'] = pd.cut(df_concat['GarageArea'], [0,200,400,600,800,1488], include_lowest=True)\n",
    "df_concat['PoolArea'] = pd.cut(df_concat['PoolArea'], [0,1,800], include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.catplot(x='PoolArea', y='SalePrice', kind='box', data=df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_num_to_cat = ['MSSubClass','OverallQual','OverallCond','BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BedroomAbvGr','KitchenAbvGr','TotRmsAbvGrd','Fireplaces','GarageCars','MoSold','YearBuilt','YearRemodAdd','YrSold','GarageYrBlt','PoolArea']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat[from_num_to_cat] = df_concat[from_num_to_cat].apply(lambda x: x.astype('category'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric variables\n",
    "numerical_features = df_concat.select_dtypes(include=[np.number])\n",
    "\n",
    "# Categorical variables\n",
    "categorical_features = df_concat.select_dtypes(exclude=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alley</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>BldgType</th>\n",
       "      <th>BsmtCond</th>\n",
       "      <th>BsmtExposure</th>\n",
       "      <th>BsmtFinType1</th>\n",
       "      <th>BsmtFinType2</th>\n",
       "      <th>BsmtFullBath</th>\n",
       "      <th>BsmtHalfBath</th>\n",
       "      <th>BsmtQual</th>\n",
       "      <th>CentralAir</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>ExterCond</th>\n",
       "      <th>ExterQual</th>\n",
       "      <th>Exterior1st</th>\n",
       "      <th>Exterior2nd</th>\n",
       "      <th>Fence</th>\n",
       "      <th>FireplaceQu</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>Foundation</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>HalfBath</th>\n",
       "      <th>Heating</th>\n",
       "      <th>HeatingQC</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>MasVnrType</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>RoofMatl</th>\n",
       "      <th>RoofStyle</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>Street</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Pave</td>\n",
       "      <td>2</td>\n",
       "      <td>TwnhsE</td>\n",
       "      <td>TA</td>\n",
       "      <td>Av</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Y</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>PConc</td>\n",
       "      <td>2</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>(2000.0, 2010.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>2Story</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Reg</td>\n",
       "      <td>160</td>\n",
       "      <td>FV</td>\n",
       "      <td>Stone</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(4.0, 8.0]</td>\n",
       "      <td>Somerst</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>Y</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Gable</td>\n",
       "      <td>Partial</td>\n",
       "      <td>New</td>\n",
       "      <td>Pave</td>\n",
       "      <td>4</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>(2000.0, 2010.0]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2fmCon</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>ALQ</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>Plywood</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>2</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>2</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>(1950.0, 1980.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>HLS</td>\n",
       "      <td>Sev</td>\n",
       "      <td>Corner</td>\n",
       "      <td>IR1</td>\n",
       "      <td>190</td>\n",
       "      <td>RL</td>\n",
       "      <td>None</td>\n",
       "      <td>Shed</td>\n",
       "      <td>(4.0, 8.0]</td>\n",
       "      <td>Timber</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Gable</td>\n",
       "      <td>Normal</td>\n",
       "      <td>WD</td>\n",
       "      <td>Grvl</td>\n",
       "      <td>7</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>(1950.0, 1980.0]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>2008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2790</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>No</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Unf</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>TA</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>MetalSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>BrkTil</td>\n",
       "      <td>1</td>\n",
       "      <td>Typ</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Fa</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>(1894.0, 1950.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1.5Fin</td>\n",
       "      <td>1</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Reg</td>\n",
       "      <td>50</td>\n",
       "      <td>RM</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(0.999, 4.0]</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Gable</td>\n",
       "      <td>Normal</td>\n",
       "      <td>WD</td>\n",
       "      <td>Pave</td>\n",
       "      <td>7</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>(1871.999, 1950.0]</td>\n",
       "      <td>(1980.0, 2000.0]</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2475</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>TA</td>\n",
       "      <td>Gd</td>\n",
       "      <td>LwQ</td>\n",
       "      <td>BLQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>HdBoard</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Po</td>\n",
       "      <td>1</td>\n",
       "      <td>CBlock</td>\n",
       "      <td>2</td>\n",
       "      <td>Typ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>(1950.0, 1980.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>GasA</td>\n",
       "      <td>TA</td>\n",
       "      <td>SLvl</td>\n",
       "      <td>1</td>\n",
       "      <td>TA</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>IR1</td>\n",
       "      <td>80</td>\n",
       "      <td>RL</td>\n",
       "      <td>BrkFace</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(4.0, 8.0]</td>\n",
       "      <td>Sawyer</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Hip</td>\n",
       "      <td>Normal</td>\n",
       "      <td>WD</td>\n",
       "      <td>Pave</td>\n",
       "      <td>5</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>(1950.0, 1980.0]</td>\n",
       "      <td>(2000.0, 2010.0]</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1240</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1Fam</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Gd</td>\n",
       "      <td>GLQ</td>\n",
       "      <td>Unf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Y</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>VinylSd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gd</td>\n",
       "      <td>1</td>\n",
       "      <td>PConc</td>\n",
       "      <td>2</td>\n",
       "      <td>Typ</td>\n",
       "      <td>3.0</td>\n",
       "      <td>TA</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>(2000.0, 2010.0]</td>\n",
       "      <td>1</td>\n",
       "      <td>GasA</td>\n",
       "      <td>Ex</td>\n",
       "      <td>1Story</td>\n",
       "      <td>1</td>\n",
       "      <td>Ex</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Reg</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>(8.0, 12.0]</td>\n",
       "      <td>NridgHt</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Y</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CompShg</td>\n",
       "      <td>Gable</td>\n",
       "      <td>Partial</td>\n",
       "      <td>New</td>\n",
       "      <td>Pave</td>\n",
       "      <td>7</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>(2000.0, 2010.0]</td>\n",
       "      <td>(-0.001, 1.0]</td>\n",
       "      <td>2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alley BedroomAbvGr BldgType BsmtCond BsmtExposure BsmtFinType1  \\\n",
       "87    Pave            2   TwnhsE       TA           Av          Unf   \n",
       "335    NaN            3   2fmCon       TA           Gd          ALQ   \n",
       "2790   NaN            3     1Fam       TA           No          Unf   \n",
       "2475   NaN            3     1Fam       TA           Gd          LwQ   \n",
       "1240   NaN            2     1Fam       Gd           Gd          GLQ   \n",
       "\n",
       "     BsmtFinType2 BsmtFullBath BsmtHalfBath BsmtQual CentralAir Condition1  \\\n",
       "87            Unf          0.0          0.0       Gd          Y       Norm   \n",
       "335           BLQ          2.0          0.0       TA          Y       Norm   \n",
       "2790          Unf          0.0          0.0       TA          Y       Norm   \n",
       "2475          BLQ          0.0          1.0       TA          Y       Norm   \n",
       "1240          Unf          1.0          0.0       Ex          Y       Norm   \n",
       "\n",
       "     Condition2 Electrical ExterCond ExterQual Exterior1st Exterior2nd Fence  \\\n",
       "87         Norm      SBrkr        TA        Gd     VinylSd     VinylSd   NaN   \n",
       "335        Norm      SBrkr        TA        TA     Plywood     Plywood   NaN   \n",
       "2790       Norm      SBrkr        Gd        TA     MetalSd     MetalSd   NaN   \n",
       "2475       Norm      SBrkr        Gd        Gd     HdBoard     HdBoard   NaN   \n",
       "1240       Norm      SBrkr        TA        Ex     VinylSd     VinylSd   NaN   \n",
       "\n",
       "     FireplaceQu Fireplaces Foundation FullBath Functional GarageCars  \\\n",
       "87           NaN          0      PConc        2        Typ        2.0   \n",
       "335           Gd          2     CBlock        2        Typ        2.0   \n",
       "2790         NaN          0     BrkTil        1        Typ        1.0   \n",
       "2475          Po          1     CBlock        2        Typ        2.0   \n",
       "1240          Gd          1      PConc        2        Typ        3.0   \n",
       "\n",
       "     GarageCond GarageFinish GarageQual GarageType       GarageYrBlt HalfBath  \\\n",
       "87           TA          RFn         TA     Detchd  (2000.0, 2010.0]        1   \n",
       "335          TA          Fin         TA     Attchd  (1950.0, 1980.0]        0   \n",
       "2790         TA          Unf         Fa     Detchd  (1894.0, 1950.0]        0   \n",
       "2475         TA          Unf         TA     Detchd  (1950.0, 1980.0]        0   \n",
       "1240         TA          Fin         TA     Attchd  (2000.0, 2010.0]        1   \n",
       "\n",
       "     Heating HeatingQC HouseStyle KitchenAbvGr KitchenQual LandContour  \\\n",
       "87      GasA        Ex     2Story            1          Gd         Lvl   \n",
       "335     GasA        Ex     1.5Fin            1          TA         HLS   \n",
       "2790    GasA        Gd     1.5Fin            1          Gd         Lvl   \n",
       "2475    GasA        TA       SLvl            1          TA         Lvl   \n",
       "1240    GasA        Ex     1Story            1          Ex         Lvl   \n",
       "\n",
       "     LandSlope LotConfig LotShape MSSubClass MSZoning MasVnrType MiscFeature  \\\n",
       "87         Gtl    Corner      Reg        160       FV      Stone         NaN   \n",
       "335        Sev    Corner      IR1        190       RL       None        Shed   \n",
       "2790       Gtl    Inside      Reg         50       RM       None         NaN   \n",
       "2475       Gtl    Inside      IR1         80       RL    BrkFace         NaN   \n",
       "1240       Gtl    Inside      Reg         20       RL        NaN         NaN   \n",
       "\n",
       "            MoSold Neighborhood OverallCond OverallQual PavedDrive  \\\n",
       "87      (4.0, 8.0]      Somerst           5           6          Y   \n",
       "335     (4.0, 8.0]       Timber           6           5          Y   \n",
       "2790  (0.999, 4.0]      BrkSide           7           5          Y   \n",
       "2475    (4.0, 8.0]       Sawyer           8           5          Y   \n",
       "1240   (8.0, 12.0]      NridgHt           5          10          Y   \n",
       "\n",
       "           PoolArea PoolQC RoofMatl RoofStyle SaleCondition SaleType Street  \\\n",
       "87    (-0.001, 1.0]    NaN  CompShg     Gable       Partial      New   Pave   \n",
       "335   (-0.001, 1.0]    NaN  CompShg     Gable        Normal       WD   Grvl   \n",
       "2790  (-0.001, 1.0]    NaN  CompShg     Gable        Normal       WD   Pave   \n",
       "2475  (-0.001, 1.0]    NaN  CompShg       Hip        Normal       WD   Pave   \n",
       "1240  (-0.001, 1.0]    NaN  CompShg     Gable       Partial      New   Pave   \n",
       "\n",
       "     TotRmsAbvGrd Utilities           YearBuilt      YearRemodAdd YrSold  \n",
       "87              4    AllPub    (2000.0, 2010.0]     (-0.001, 1.0]   2009  \n",
       "335             7    AllPub    (1950.0, 1980.0]     (-0.001, 1.0]   2008  \n",
       "2790            7    AllPub  (1871.999, 1950.0]  (1980.0, 2000.0]   2006  \n",
       "2475            5    AllPub    (1950.0, 1980.0]  (2000.0, 2010.0]   2007  \n",
       "1240            7    AllPub    (2000.0, 2010.0]     (-0.001, 1.0]   2006  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>Id</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>TotalPorchSF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>336.0</td>\n",
       "      <td>1216</td>\n",
       "      <td>1750</td>\n",
       "      <td>9000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>662.0</td>\n",
       "      <td>1290</td>\n",
       "      <td>1869</td>\n",
       "      <td>6762</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1282.0</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1653</th>\n",
       "      <td>440.0</td>\n",
       "      <td>1456</td>\n",
       "      <td>1658</td>\n",
       "      <td>2364</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>855.0</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013</th>\n",
       "      <td>384.0</td>\n",
       "      <td>984</td>\n",
       "      <td>2018</td>\n",
       "      <td>9100</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>984.0</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>313.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>2616</td>\n",
       "      <td>10533</td>\n",
       "      <td>85.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      GarageArea  GrLivArea    Id  LotArea  LotFrontage  MasVnrArea  \\\n",
       "1745       336.0       1216  1750     9000         75.0       200.0   \n",
       "1864       662.0       1290  1869     6762         64.0         0.0   \n",
       "1653       440.0       1456  1658     2364         24.0         0.0   \n",
       "2013       384.0        984  2018     9100         70.0         0.0   \n",
       "2611       313.0       1024  2616    10533         85.0       244.0   \n",
       "\n",
       "      SalePrice  TotalBsmtSF  TotalPorchSF  \n",
       "1745        NaN       1216.0             0  \n",
       "1864        NaN       1282.0           168  \n",
       "1653        NaN        855.0           147  \n",
       "2013        NaN        984.0           201  \n",
       "2611        NaN       1008.0           280  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log transform numerical predictors with the highest correlation with target \n",
    "df_concat['GrLivArea'] = np.log(df_concat['GrLivArea'])\n",
    "df_concat['LotArea'] = np.log(df_concat['LotArea'])\n",
    "df_concat['LotFrontage'] = np.log(df_concat['LotFrontage'])\n",
    "\n",
    "# has zeros\n",
    "#df_concat['TotalBsmtSF'] = np.log(df_concat['TotalBsmtSF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat['Alley'].fillna('NoAlley', inplace = True)\n",
    "df_concat['BsmtQual'].fillna('NoBsmt', inplace = True)\n",
    "df_concat['BsmtCond'].fillna('NoBsmt', inplace = True)\n",
    "df_concat['BsmtExposure'].fillna('NoBsmt', inplace = True)\n",
    "df_concat['BsmtFinType1'].fillna('NoBsmt', inplace = True)\n",
    "df_concat['BsmtFinType2'].fillna('NoBsmt', inplace = True)\n",
    "df_concat['FireplaceQu'].fillna('NoFirePl', inplace = True)\n",
    "df_concat['GarageType'].fillna('NoGarage', inplace = True)\n",
    "df_concat['GarageFinish'].fillna('NoGarage', inplace = True)\n",
    "df_concat['GarageQual'].fillna('NoGarage', inplace = True)\n",
    "df_concat['GarageCond'].fillna('NoGarage', inplace = True)\n",
    "df_concat['PoolQC'].fillna('NoPool', inplace = True)\n",
    "df_concat['Fence'].fillna('NoFence', inplace = True)\n",
    "df_concat['MiscFeature'].fillna('NoMiscFeature', inplace = True)\n",
    "df_concat['MasVnrType'].fillna('NoVeneer', inplace = True)\n",
    "df_concat['MasVnrType'].replace('None','NoVeneer', inplace=True) # None means there is no veneer. Pass None to category NoVeneer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice       1459\n",
       "Exterior1st        0\n",
       "Fence              0\n",
       "FireplaceQu        0\n",
       "Fireplaces         0\n",
       "Foundation         0\n",
       "FullBath           0\n",
       "Functional         0\n",
       "GarageArea         0\n",
       "TotalPorchSF       0\n",
       "GarageCars         0\n",
       "GarageCond         0\n",
       "GarageFinish       0\n",
       "GarageQual         0\n",
       "GarageType         0\n",
       "GarageYrBlt        0\n",
       "GrLivArea          0\n",
       "Exterior2nd        0\n",
       "ExterQual          0\n",
       "Heating            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_concat.isnull().sum().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_concat_dummified = pd.get_dummies(df_concat, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hilmiuysal\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# Now, we do not have any nulls. Time to split between train and test.\n",
    "test = df_concat_dummified.loc[df_concat.SalePrice.isnull(),]\n",
    "train = df_concat_dummified.loc[~df_concat.SalePrice.isnull(),]\n",
    "test.drop('SalePrice', inplace=True, axis=1)\n",
    "test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1459, 322)\n",
      "(1456, 323)\n"
     ]
    }
   ],
   "source": [
    "print(test.shape)\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['Id'] = test.Id\n",
    "\n",
    "Y=train['SalePrice']\n",
    "X=train.loc[:, ~train.columns.isin(['Id','SalePrice'])]\n",
    "test2=test.loc[:, ~test.columns.isin(['Id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1456, 321)\n",
      "(1459, 321)\n",
      "set()\n",
      "0\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "# Before fitting to models, check shape of datasets.\n",
    "print(X.shape)\n",
    "print(test2.shape)\n",
    "print(set(X.columns) - set(test2.columns))\n",
    "print(len(set(X.columns) - set(test2.columns)))\n",
    "print(set(test2.columns) - set(X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use cross_val_score for its simplicity to estimate MSE for different models.\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state=42, test_size=.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R^2 for MLR is: 0.95154\n",
      "Test Scores: [-3.97566024e+20 -1.96543810e+21 -7.48503343e+23 -3.85233276e+21\n",
      " -2.11994905e+21 -5.54291119e+21 -6.98714005e+20 -1.84971640e+21\n",
      " -2.14739602e+21 -2.02335883e+21]\n",
      "Mean of Test Scores: -7.691007255023796e+22\n",
      "Std. Deviation of Test Scores: 2.23868791151652e+23\n"
     ]
    }
   ],
   "source": [
    "# MLR\n",
    "if 'MLR' in model_list:\n",
    "    \n",
    "# looking at the results, we choose to run Ridge regression with below settings:\n",
    "#mlr_selected = RidgeCV(alphas=[0], cv=10, normalize=True, fit_intercept=True)\n",
    "#mlr_selected.fit(X, Y)\n",
    "\n",
    "#y_pred_ridge = mlr_selected.predict(test2)\n",
    "\n",
    "    lm = Ridge(alpha = 0)\n",
    "    lm.fit(X, Y)\n",
    "    scores = cross_val_score(estimator=lm, X=X_train, y=Y_train, cv=10)\n",
    "    #cv_list = [3, 5, 10]\n",
    "    print('Best R^2 for MLR is: %.5f' %(lm.score(X,Y)))\n",
    "    print('Test Scores: {}'.format(scores))\n",
    "    print('Mean of Test Scores: {}'.format(scores.mean()))\n",
    "    print('Std. Deviation of Test Scores: {}'.format(scores.std()))\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ridge with Cross Validation\n",
    "\n",
    "# String to Boolean\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"true\")\n",
    "\n",
    "\n",
    "if 'Ridge' in model_list:\n",
    "    \n",
    "    # Alpha range\n",
    "    alphas = np.linspace(0.01, 5, 200)\n",
    "    \n",
    "    # CV range\n",
    "    sqrt_n = int(np.sqrt(len(X_train))) # Square root of # of obs. (CV = 31)\n",
    "    cv_list = [None, 3, 5, 10, sqrt_n]\n",
    "    CV_index = []\n",
    "    \n",
    "    # Normalization\n",
    "    norm_list = ['False', 'True']\n",
    "    norm_list2 = []\n",
    "    \n",
    "    # Intercept\n",
    "    intercept_list = ['False', 'True']\n",
    "    intercept_list2 = []\n",
    "    \n",
    "    # Initialization of lists to be added to dict_\n",
    "    best_alphas = []\n",
    "    best_R2s = []\n",
    "    best_MSEs = []\n",
    "    mean_CVscores = []\n",
    "    std_CVscores = []\n",
    "    \n",
    "    # Initialization of dictionary object to cast to df\n",
    "    dict_ = {}\n",
    "    \n",
    "    # Loop for different values of CV and normalization type using the alpha range specified\n",
    "    for cv in cv_list:\n",
    "        for norm in norm_list:\n",
    "            for intercept in intercept_list:\n",
    "            \n",
    "                if cv == None:\n",
    "                    cv_name = 'LOOCV' # Leave one out CV (Generalized Cross Validation)\n",
    "                else:\n",
    "                    cv_name = str(cv)\n",
    "                    \n",
    "                print('CV: %s' %cv_name)\n",
    "                print('Normalize: %s' %norm)\n",
    "                print('Intercept: %s' %intercept)\n",
    "\n",
    "                ridgeCV = RidgeCV(alphas=alphas, cv=cv, normalize=str2bool(norm), fit_intercept=str2bool(intercept), scoring = 'neg_mean_squared_error')\n",
    "                ridgeCV.fit(X_train,Y_train)\n",
    "                y_pred_ridge = ridgeCV.predict(test2)\n",
    "                print('Best alpha for Ridge is: %.2f' %(ridgeCV.alpha_))\n",
    "                print('Best R^2 for Ridge is: %.5f' %(ridgeCV.score(X_train,Y_train)))\n",
    "\n",
    "                best_alphas.append(round(ridgeCV.alpha_, 2))\n",
    "                best_R2s.append(round(ridgeCV.score(X_train,Y_train), 5))\n",
    "\n",
    "                ridge = Ridge(alpha = ridgeCV.alpha_, normalize = str2bool(norm), fit_intercept=str2bool(intercept))\n",
    "                ridge.fit(X_train, Y_train)\n",
    "                mse = round(mean_squared_error(Y_test, ridge.predict(X_test)), 5)\n",
    "                print('MSE for Ridge: %.5f' %mse)\n",
    "\n",
    "                best_MSEs.append(mse)\n",
    "                \n",
    "                if cv == None:\n",
    "                    cv_new = len(X_train)\n",
    "                    scores = cross_val_score(estimator=ridge, X=X_train, y=Y_train, cv=cv_new) # Estimate score using cv = (# of obs.)\n",
    "                else:\n",
    "                    scores = cross_val_score(estimator=ridge, X=X_train, y=Y_train, cv=cv) # Estimate score using cv = (# of obs.)\n",
    "                \n",
    "                # Estimate test scores using cross_val_score\n",
    "                scores = np.array(list(map(lambda x: round(x,5), scores)))\n",
    "                avg_score = round(scores.mean(), 5)\n",
    "                std_score = round(scores.std(), 5)\n",
    "                print('Test Scores: {}'.format(scores))\n",
    "                print('Mean of Test Scores: {}'.format(avg_score))\n",
    "                print('Std. Deviation of Test Scores: {}'.format(std_score))\n",
    "                print('*' * 50, '\\n')\n",
    "\n",
    "                mean_CVscores.append(avg_score)\n",
    "                std_CVscores.append(std_score)\n",
    "                \n",
    "                CV_index.append('CV_' + cv_name)\n",
    "                norm_list2.append(norm)\n",
    "                intercept_list2.append(intercept)\n",
    "\n",
    "                dict_['Norm_Type'] = norm_list2\n",
    "                dict_['Intercept_Type'] = intercept_list2\n",
    "                dict_['best_alphas'] = best_alphas\n",
    "                dict_['best_R2s'] = best_R2s\n",
    "                dict_['best_MSEs'] = best_MSEs\n",
    "                dict_['mean_CVscores'] = mean_CVscores\n",
    "                dict_['std_CVscores'] = std_CVscores\n",
    "\n",
    "                #print(dict_)\n",
    "\n",
    "    df_results = pd.DataFrame(dict_, index=CV_index)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    df_results.rename({'index':'CV'}, axis=1, inplace=True) #rename index as CV\n",
    "    #df_results.sort_values(by=['best_MSEs', 'mean_CVscores'], ascending=[True,False], inplace=True)\n",
    "    print(df_results)\n",
    "\n",
    "    # looking at the results, we choose to run Ridge regression with below settings:\n",
    "    ridge_selected = RidgeCV(alphas=[0.16], cv=10, normalize=True, fit_intercept=True)\n",
    "    ridge_selected.fit(X, Y)\n",
    "    y_pred_ridge = ridge_selected.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lasso with Cross Validation\n",
    "\n",
    "# String to Boolean\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"true\")\n",
    "\n",
    "\n",
    "if 'Lasso' in model_list:\n",
    "    \n",
    "    # Alpha range\n",
    "    alphas = np.logspace(-1, 1, 200)\n",
    "    \n",
    "    # CV range\n",
    "    sqrt_n = int(np.sqrt(len(X_train))) # Square root of # of obs. (CV = 31)\n",
    "    cv_list = [None, 3, 5, 10, sqrt_n]\n",
    "    CV_index = []\n",
    "    \n",
    "    # Normalization\n",
    "    norm_list = ['False', 'True']\n",
    "    norm_list2 = []\n",
    "    \n",
    "    # Intercept\n",
    "    intercept_list = ['False', 'True']\n",
    "    intercept_list2 = []\n",
    "    \n",
    "    # Initialization of lists to be added to dict_\n",
    "    best_alphas = []\n",
    "    best_R2s = []\n",
    "    best_MSEs = []\n",
    "    mean_CVscores = []\n",
    "    std_CVscores = []\n",
    "    \n",
    "    # Initialization of dictionary object to cast to df\n",
    "    dict_ = {}\n",
    "    \n",
    "    # Loop for different values of CV and normalization type using the alpha range specified\n",
    "    for cv in cv_list:\n",
    "        for norm in norm_list:\n",
    "            for intercept in intercept_list:\n",
    "            \n",
    "                if cv == None:\n",
    "                    cv_name = 'LOOCV' # Leave one out CV (Generalized Cross Validation)\n",
    "                else:\n",
    "                    cv_name = str(cv)\n",
    "                    \n",
    "                print('CV: %s' %cv_name)\n",
    "                print('Normalize: %s' %norm)\n",
    "                print('Intercept: %s' %intercept)\n",
    "\n",
    "                lassoCV = LassoCV(alphas=alphas, cv=cv, normalize=str2bool(norm), fit_intercept=str2bool(intercept))\n",
    "                lassoCV.fit(X_train,Y_train)\n",
    "                #y_pred_Lasso = lassoCV.predict(test2)\n",
    "                print('Best alpha for Lasso is: %.2f' %(lassoCV.alpha_))\n",
    "                print('Best R^2 for Lasso is: %.5f' %(lassoCV.score(X_train,Y_train)))\n",
    "\n",
    "                best_alphas.append(round(lassoCV.alpha_, 2))\n",
    "                best_R2s.append(round(lassoCV.score(X_train,Y_train), 5))\n",
    "\n",
    "                lasso = Lasso(alpha = lassoCV.alpha_, normalize = str2bool(norm), fit_intercept=str2bool(intercept))\n",
    "                lasso.fit(X_train, Y_train)\n",
    "                mse = round(mean_squared_error(Y_test, lasso.predict(X_test)), 5)\n",
    "                print('MSE for Lasso: %.5f' %mse)\n",
    "\n",
    "                best_MSEs.append(mse)\n",
    "                \n",
    "                if cv == None:\n",
    "                    cv_new = len(X_train)\n",
    "                    scores = cross_val_score(estimator=lasso, X=X_train, y=Y_train, cv=cv_new) # Estimate score using cv = (# of obs.)\n",
    "                else:\n",
    "                    scores = cross_val_score(estimator=lasso, X=X_train, y=Y_train, cv=cv) # Estimate score using cv = (# of obs.)\n",
    "                \n",
    "                # Estimate test scores using cross_val_score\n",
    "                scores = np.array(list(map(lambda x: round(x,5), scores)))\n",
    "                avg_score = round(scores.mean(), 5)\n",
    "                std_score = round(scores.std(), 5)\n",
    "                print('Test Scores: {}'.format(scores))\n",
    "                print('Mean of Test Scores: {}'.format(avg_score))\n",
    "                print('Std. Deviation of Test Scores: {}'.format(std_score))\n",
    "                print('*' * 50, '\\n')\n",
    "\n",
    "                mean_CVscores.append(avg_score)\n",
    "                std_CVscores.append(std_score)\n",
    "                \n",
    "                CV_index.append('CV_' + cv_name)\n",
    "                norm_list2.append(norm)\n",
    "                intercept_list2.append(intercept)\n",
    "\n",
    "                dict_['Norm_Type'] = norm_list2\n",
    "                dict_['Intercept_Type'] = intercept_list2\n",
    "                dict_['best_alphas'] = best_alphas\n",
    "                dict_['best_R2s'] = best_R2s\n",
    "                dict_['best_MSEs'] = best_MSEs\n",
    "                dict_['mean_CVscores'] = mean_CVscores\n",
    "                dict_['std_CVscores'] = std_CVscores\n",
    "\n",
    "                #print(dict_)\n",
    "\n",
    "    df_results = pd.DataFrame(dict_, index=CV_index)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    df_results.rename({'index':'CV'}, axis=1, inplace=True) #rename index as CV\n",
    "    #df_results.sort_values(by=['best_MSEs', 'mean_CVscores'], ascending=[True,False], inplace=True)\n",
    "    print(df_results)\n",
    "\n",
    "    # looking at the results, we choose to run Lasso regression with below settings:\n",
    "    lasso_selected = LassoCV(alphas=[0.1], cv=5, normalize=False, fit_intercept=True)\n",
    "    lasso_selected.fit(X, Y)\n",
    "    y_pred_lasso = lasso_selected.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ElasticNetCV with Cross Validation\n",
    "\n",
    "# String to Boolean\n",
    "def str2bool(v):\n",
    "    return v.lower() in (\"true\")\n",
    "\n",
    "\n",
    "if 'ElasticNet' in model_list:\n",
    "    \n",
    "    # Alpha range\n",
    "    alphas = np.linspace(0.1, 10, 100)\n",
    "\n",
    "    # Rho ranges\n",
    "    rhos   = np.linspace(0.01, 1, 100)\n",
    "    \n",
    "    # CV range\n",
    "    sqrt_n = int(np.sqrt(len(X_train))) # Square root of # of obs. (CV = 31)\n",
    "    cv_list = [3, 5, 10, sqrt_n] # If None alphas are set automatically. So, drop it!\n",
    "    CV_index = []\n",
    "    \n",
    "    # Normalization\n",
    "    norm_list = ['False', 'True']\n",
    "    norm_list2 = []\n",
    "    \n",
    "    # Intercept\n",
    "    intercept_list = ['False', 'True']\n",
    "    intercept_list2 = []\n",
    "    \n",
    "    # Initialization of lists to be added to dict_\n",
    "    best_alphas = []\n",
    "    best_rhos = []\n",
    "    best_R2s = []\n",
    "    best_MSEs = []\n",
    "    mean_CVscores = []\n",
    "    std_CVscores = []\n",
    "    \n",
    "    # Initialization of dictionary object to cast to df\n",
    "    dict_ = {}\n",
    "    \n",
    "    # Loop for different values of CV and normalization type using the alpha range specified\n",
    "    for cv in cv_list:\n",
    "        for norm in norm_list:\n",
    "            for intercept in intercept_list:\n",
    "            \n",
    "                if cv == None:\n",
    "                    cv_name = 'LOOCV' # Leave one out CV (Generalized Cross Validation)\n",
    "                else:\n",
    "                    cv_name = str(cv)\n",
    "                    \n",
    "                print('CV: %s' %cv_name)\n",
    "                print('Normalize: %s' %norm)\n",
    "                print('Intercept: %s' %intercept)\n",
    "\n",
    "                elasticNetCV = ElasticNetCV(l1_ratio=rhos, alphas=alphas, cv=cv, normalize=str2bool(norm), fit_intercept=str2bool(intercept), max_iter=10000)\n",
    "                elasticNetCV.fit(X_train,Y_train)\n",
    "                #y_pred_elastic = elasticNetCV.predict(test2)\n",
    "                print('Best alpha for ElasticNetCV is: %.2f' %(elasticNetCV.alpha_))\n",
    "                print('Best rho for ElasticNetCV is: %.2f' %(elasticNetCV.l1_ratio_))\n",
    "                print('Best R^2 for ElasticNetCV is: %.5f' %(elasticNetCV.score(X_train,Y_train)))\n",
    "\n",
    "                best_alphas.append(round(elasticNetCV.alpha_, 2))\n",
    "                best_rhos.append(round(elasticNetCV.l1_ratio_, 2))\n",
    "                best_R2s.append(round(elasticNetCV.score(X_train,Y_train), 5))\n",
    "\n",
    "                elasticnet = ElasticNet(l1_ratio=elasticNetCV.l1_ratio_, alpha = elasticNetCV.alpha_, normalize = str2bool(norm), fit_intercept=str2bool(intercept), max_iter=10000)\n",
    "                elasticnet.fit(X_train, Y_train)\n",
    "                mse = round(mean_squared_error(Y_test, elasticnet.predict(X_test)), 5)\n",
    "                print('MSE for ElasticNet: %.5f' %mse)\n",
    "\n",
    "                best_MSEs.append(mse)\n",
    "                \n",
    "                if cv == None:\n",
    "                    cv_new = len(X_train)\n",
    "                    scores = cross_val_score(estimator=elasticnet, X=X_train, y=Y_train, cv=cv_new) # Estimate score using cv = (# of obs.)\n",
    "                else:\n",
    "                    scores = cross_val_score(estimator=elasticnet, X=X_train, y=Y_train, cv=cv) # Estimate score using cv = (# of obs.)\n",
    "                \n",
    "                # Estimate test scores using cross_val_score\n",
    "                scores = np.array(list(map(lambda x: round(x,5), scores)))\n",
    "                avg_score = round(scores.mean(), 5)\n",
    "                std_score = round(scores.std(), 5)\n",
    "                print('Test Scores: {}'.format(scores))\n",
    "                print('Mean of Test Scores: {}'.format(avg_score))\n",
    "                print('Std. Deviation of Test Scores: {}'.format(std_score))\n",
    "                print('*' * 50, '\\n')\n",
    "\n",
    "                mean_CVscores.append(avg_score)\n",
    "                std_CVscores.append(std_score)\n",
    "                \n",
    "                CV_index.append('CV_' + cv_name)\n",
    "                norm_list2.append(norm)\n",
    "                intercept_list2.append(intercept)\n",
    "\n",
    "                dict_['Norm_Type'] = norm_list2\n",
    "                dict_['Intercept_Type'] = intercept_list2\n",
    "                dict_['best_alphas'] = best_alphas\n",
    "                dict_['best_rhos'] = best_rhos\n",
    "                dict_['best_R2s'] = best_R2s\n",
    "                dict_['best_MSEs'] = best_MSEs\n",
    "                dict_['mean_CVscores'] = mean_CVscores\n",
    "                dict_['std_CVscores'] = std_CVscores\n",
    "\n",
    "                #print(dict_)\n",
    "\n",
    "    df_results = pd.DataFrame(dict_, index=CV_index)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    df_results.rename({'index':'CV'}, axis=1, inplace=True) #rename index as CV\n",
    "    #df_results.sort_values(by=['best_MSEs', 'mean_CVscores'], ascending=[True,False], inplace=True)\n",
    "    print(df_results)\n",
    "\n",
    "    # looking at the results, we choose to run ElasticNet regression with below settings:\n",
    "    elas_selected = ElasticNetCV(l1_ratio=[0.1], alphas=[0.1], cv=5, normalize=False, fit_intercept=True)\n",
    "    elas_selected.fit(X, Y)\n",
    "    y_pred_elastic = elas_selected.predict(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "if 'RandomForest' in model_list:\n",
    "    \n",
    "    from sklearn import ensemble\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    \n",
    "    \n",
    "    best_R2s = []\n",
    "    mean_CVscores = []\n",
    "    std_CVscores = []\n",
    "    best_MSEs = []\n",
    "    \n",
    "    # Initialization of dictionary object to cast to df\n",
    "    dict_ = {}\n",
    "\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    pprint.pprint(random_grid)\n",
    "\n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestRegressor()\n",
    "    # Random search of parameters, using 10 fold cross validation, \n",
    "    # search across 10 different combinations, and use all available cores\n",
    "    cv_list = [3, 5, 10]\n",
    "    CV_index = []\n",
    "    \n",
    "    for cv in cv_list:\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = cv, verbose=2, random_state=42, n_jobs = -1)\n",
    "        # Test scores\n",
    "        scores = cross_val_score(estimator=rf, X=X_train, y=Y_train, cv=cv)\n",
    "        avg_score = round(scores.mean(), 5)\n",
    "        std_score = round(scores.std(), 5)\n",
    "        print('Test Scores: {}'.format(scores))\n",
    "        print('Mean of Test Scores: {}'.format(scores.mean()))\n",
    "        print('Std. Deviation of Test Scores: {}'.format(scores.std()))\n",
    "        \n",
    "        rf_random.fit(X_train, Y_train)\n",
    "        print('Best R^2 for RandomForest is: %.5f' %(rf_random.score(X_train,Y_train)))\n",
    "        \n",
    "        \n",
    "        #rf = RandomForestRegressor()\n",
    "        #rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 5, verbose=2, random_state=42, n_jobs = -1)\n",
    "        #rf_random.fit(X_train, Y_train)\n",
    "        mse = round(mean_squared_error(Y_test, rf_random.predict(X_test)), 5)\n",
    "        print('MSE for RF: %.5f' %mse)\n",
    "        best_MSEs.append(mse)\n",
    "        \n",
    "        best_R2s.append(round(rf_random.score(X_train,Y_train), 5))\n",
    "        mean_CVscores.append(avg_score)\n",
    "        std_CVscores.append(std_score)\n",
    "    \n",
    "        dict_['best_R2s'] = best_R2s\n",
    "        dict_['mean_CVscores'] = mean_CVscores\n",
    "        dict_['std_CVscores'] = std_CVscores\n",
    "        dict_['best_MSEs'] = best_MSEs\n",
    "        \n",
    "        CV_index.append('CV_' + str(cv))\n",
    "    \n",
    "    df_results = pd.DataFrame(dict_, index=CV_index)\n",
    "    df_results.reset_index(inplace=True)\n",
    "    df_results.rename({'index':'CV'}, axis=1, inplace=True) #rename index as CV\n",
    "    #df_results.sort_values(by=['best_MSEs', 'mean_CVscores'], ascending=[True,False], inplace=True)\n",
    "    print(df_results)\n",
    "    \n",
    "    # looking at the results, we choose to run RandomForest regression using below settings:\n",
    "    rf = RandomForestRegressor()\n",
    "    rf_selected = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 5, cv = 10, verbose=2, random_state=42, n_jobs = -1)\n",
    "    rf_selected.fit(X,Y)\n",
    "    y_pred_rf = rf_selected.predict(test2)\n",
    "    \n",
    "    \n",
    "    mse = round(mean_squared_error(Y_test, rf_random.predict(X_test)), 5)\n",
    "    print('MSE for RF: %.5f' %mse)\n",
    "    #best_MSEs.append(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "if 'XGBoost' in model_list:\n",
    "\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    X.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\n",
    "    test2.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in test2.columns.values]    \n",
    "\n",
    "    #xgb = xgb.XGBRegressor()\n",
    "    #xgb.fit(X, Y)\n",
    "    #y_pred_xgb = xgb.predict(test2)\n",
    "    #mse=mean_squared_error(Y, xgb.predict(X))\n",
    "    #print('Best R^2 for XGBoost is: %.5f' %(xgb.score(X, Y)))\n",
    "    #print('RMSE is: ', np.sqrt(mse))\n",
    "\n",
    "    params = {\n",
    "    \"colsample_bytree\": [0.5,1],\n",
    "    \"gamma\": [0,0.1,0.2,0.3,0.4,0.5],\n",
    "    \"learning_rate\": [0.05, 0.1, 0.2, 0.3], # default 0.1 \n",
    "    \"max_depth\": [3,4,5,6,7,8,9,10], # default 3\n",
    "    \"n_estimators\": [100,110,120,130,140,150], # default 100\n",
    "    \"subsample\": [0.5,1]\n",
    "    }\n",
    "\n",
    "    xgb_search = RandomizedSearchCV(xgb, param_distributions=params, random_state=42, n_iter=10, cv=3, verbose=1, n_jobs=1, return_train_score=True)\n",
    "    xgb_search.fit(X, Y)\n",
    "    y_pred_xgb = xgb_search.predict(test2)\n",
    "    print(xgb_search.cv_results_, 1)\n",
    "    print(xgb_search.best_params_)\n",
    "    print(\"best score: {0}\".format(xgb_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to CSV\n",
    "for model in model_list:\n",
    "    \n",
    "    if model == 'MLR':\n",
    "        y_pred = y_pred_mlr\n",
    "    elif model == 'Ridge':\n",
    "        y_pred = y_pred_ridge\n",
    "    elif model == 'BayesianRidge':\n",
    "        y_pred = y_pred_bridge\n",
    "    elif model == 'Lasso':\n",
    "        y_pred = y_pred_lasso\n",
    "    elif model == 'ElasticNet':\n",
    "        y_pred = y_pred_elastic\n",
    "    elif model == 'RandomForest':\n",
    "        y_pred = y_pred_rf\n",
    "#    else:\n",
    "#        y_pred = y_pred_xgb\n",
    "\n",
    "    if submission.columns.isin(['SalePrice']).any():\n",
    "        submission.drop('SalePrice', inplace=True, axis=1)\n",
    "    \n",
    "    submission['SalePrice'] = pd.Series(np.exp(y_pred))\n",
    "    filename = 'SalePrice_Prediction_' + model + '.csv'\n",
    "    submission.to_csv(filename, index=False)\n",
    "    \n",
    "    fname_cv_results = 'Results_' + model + '.csv'\n",
    "    df_results.to_csv(fname_cv_results, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
